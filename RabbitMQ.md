# RabbitMQ 分享

## 1 内容列表
- [1 内容列表](#1-内容列表)
- [2 什么是消息队列?](#2-什么是消息队列)
- [3 为什么会有消息队列?](#3-为什么要有消息队列)
- [4 消息队列产生前都是怎样玩的?](#4-消息队列产生前都是怎样玩的)
- [5 什么是RabbitMQ?](#5-什么是RabbitMQ)
- [6 为什么会有RabbitMQ?](#6-为什么会有RabbitMQ)
	- [6.1 救世主AMQP](#6.1-救世主AMQP)
	- [6.2 RabbitMQ简史](#6.2-RabbitMQ简史)
- [7 如何选择消息队列?](#7-如何选择消息队列)
	- [7.1 RabbitMQ](#7.1-RabbitMQ)
	- [7.2 RocketMQ](#7.2-RocketMQ)
	- [7.3 Kafka](#7.3-Kafka)
	- [7.4 总结](#7.4-总结)
- [8 消息对列模型](#8-消息对列模型)
	- [8.1 队列模型](#8.1-队列模型)
	- [8.2 发布订阅模型](#8.2-发布订阅模型)
- [9 如何确保消息不会丢失?](#9-如何确保消息不会丢失)
- [10 如何处理消费过程中的重复消息?](#10-如何处理消费过程中的重复消息)
- [11 消息积压了该如何处理?](#11-消息积压了该如何处理)
- [12 实现消息队列的一些技术](#12-实现消息队列的一些技术)
- [13 RabbitMQ基本操作](#13-RabbitMQ基本操作)

## 2 什么是消息队列？
消息排队允许应用程序通过相互发送消息进行通信。当目标程序繁忙或未连接时，消息队列将提供临时消息存储[1]。
消息队列是一种异步的服务间通信方式，适用于无服务器和微服务架构。消息在被处理和删除之前一直存储在队列上。每条消息仅可被一位用户处理一次。消息队列可被用于分离重量级处理、缓冲或批处理工作以及缓解高峰期工作负载[2]。
![message queue](https://github.com/meiyingqishi/Images/blob/main/message-queue-small.png)

## 3 为什么会有消息队列？
为了获得[3]：

- **更好的性能：**消息队列支持异步通信，这意味着创建和处理消息的终端节点将与队列进行交互，而不是彼此交互。创建器可以将请求添加到队列中，无需再等待这些请求接受处理。处理器仅在消息可用时才会处理消息。系统中的任何组件都不会停下等待其他组件，从而优化了数据流。

- **增强的可靠性：**队列可永久保留您的数据，并减少系统的不同部件离线时发生的错误。通过利用消息队列分离不同的组件，可以提高容错性。即使系统的某一部分无法访问，其他部分也仍可继续与队列进行交互。队列本身也可以进行镜像，以提供更高的可用性。

- **细化的可扩展性：**消息队列可根据您的需要精确扩展。当工作负载到达峰值时，应用程序的多个实例都可以将请求添加到队列，而且不会产生冲突。随着队列因这些传入请求的增多而越来越长，您可以将这些工作负载分发给一组处理器。创建器、处理器和队列本身都可以按需扩展和缩减。

- **简化的分离功能：**消息队列消除了组件之间的依赖关系，并显著简化了分离应用程序的编码。软件组件不必承担通信代码的重压，而是可以在经过设计后执行离散的业务功能。

## 4 消息队列产生前都是怎样玩的？
当大量写请求，或者具体的说应该是瞬时大量的写请求到来时，既要保证系统的可用性还要保证尽量全部处理掉请求的情况下，我们应该怎么处理呢？
- **线程池**：池化技术在我们日常开发中是缓解系统压力的一个重要利器，但是对于线程池而言很难根据系统的瞬时流量来自动伸缩容量，而且自动伸缩流量并不是根治大流量到来办法。当池子满了以后也会影响部分情况的丢弃，最重要的是一旦服务宕机，那么所有的请求将化为乌有，除非你将线程池序列化，自己想想复杂度跟性能吧。
- **队列/缓存**：队列一般场景下都是使用空间换时间的另一种常用办法，但是它的弊病也存在需要自己开发一套序列化方案，保证服务异常恢复能正常处理后续任务。Redis的发布订阅者同样存在这些问题。

## 5 什么是RabbitMQ？
RabbitMQ是一个免费的，开源的，可扩展的消息队列解决方案。 它是一个消息代理，可以理解AMQP（高级消息队列协议），但也可以与其他流行的消息解决方案（例如MQTT）一起使用。 它具有高可用性、容错性和可扩展性。 它在Erlang OTP中实现，该技术专为构建稳定、可靠、容错和高度可扩展的系统而设计，该系统具有处理大量并发操作的本机功能，例如RabbitMQ和其他系统（例如WhatsApp、MongooseIM等几个）。

在非常高的层次上，它是一个中间件层，使您的应用程序中的不同服务可以彼此通信，而不必担心消息丢失，同时提供不同的服务质量（QoS）要求。 它还可以实现细粒度和高效的消息路由，从而实现应用程序的广泛解耦[4]。

![rabbitmq flow](https://github.com/meiyingqishi/Images/blob/main/workflow-rabbitmq.png)

## 6 为什么会有RabbitMQ？ 
在1983年，以为来自孟买的26岁软件工程师脑海里浮现了一个激进的想法：为社么没有一种通用的软件总线---一种通信系统，可以解决应用程序间繁重的信息通信工作呢？来自MIT的硬件设计教育工作者Vivek Ranadive设想了一种通用软件总线，就像主板上的总线那样供其它应用程序接入，因此，在1983年Teknekron诞生了。受伤掌握着崭新的哈佛MBA证书，脑袋里拥有强大的想法，Vivek为世界上各地的开发者开垦了一条捷径。

拥有美好的想法是一回事，而为它找到杀手级的应用则是另一回事。在1985年的高盛，Ranadive找到了它的第一位客户以及软件总线天生用来解决的问题：金融交易。当交易员的小隔间内挤满了用来完成交易的不同终端，每台终端上显示着不同类型的信息。Teknekron发觉这是个机会：替换掉所有那些终端和孤立的应用程序。在交易员的位置上的将会是Ranadive的软件总线。而桌上只会剩下一台工作站。而工作站的显示程序可以作为消费者接入Teknekron软件总线，并允许交易员“订阅”他想要看到的信息。于是发布订阅模式（PubSub)诞生了，同时还诞生了世界上第一个现代消息队列软件：Teknekron的The Information Bus（TIB）。

用不了多久，这种数据传输模型就找到了更多杀手级用途。最终，发布数据的应用和消费数据的应用再也不用直接连接在一起了。他们甚至都不需要对方的存在。Teknekron的TIB允许应用开发者建立一系列规则去描述消息内容。只要消息按照这些规则发布出去，任何消费者应用都能订阅感兴趣的消息。现在，信息的生产者和消费者之间完全解耦，并且可以在传输过程中灵活混合。PubSub模型的任意一边可以完全互换而不会影响到另一边。唯一需要保持未定的是TIB软件以及标记和路由信息规则。由于在那个时期金融交易行业门庭若市，因此TIB迅速传播开来。它引起了电信特别是新闻机构的注意。这些行业也特别需要将信息及时发布给千变万化的客户。这也解释了为什么在1994年大型新闻机构路透社收购了Teknekron。

与此同时，这个迅猛发展的企业软件引起了蓝色巨人的注意。毕竟IBM最大的几位客户都来自金融服务行业。而且，Teknekron的TIB软件通常会运行在IBM的硬件和操作系统上。除了White Plains的那群孩子外所有人都从中获得了好处。因此20世纪80年代后期，IBM开始研究开发自己的消息队列软件，运用他们在开发DB2时信息投递的丰富经验。开发工作起始于1990年，就在IBM的英国温切斯特附近的Hursely公园实验室。3年后，消息对列服务器软件IBM MQ产品系列面世。之后的17年，MQ系列进化成了WebSphere MQ并统治着商业消息队列平台市场。在那段时间，Ranadive的TIB并没有消失在路透腹中。相反，它仍然是企业通信市场的主要参与者，并且通过更名为Rendezvous而走向繁荣。在1997年Teknekron以TIBCO的形式作为一家独立公司再度出现。同年，微软也在消息通信市场展露头角：微软消息队列（MSMQ）。

通过这一系列的革新，消息队列软件主要留住了大型机构，它们需要可靠性、解耦以及实时消息通信。为什么MQ不去寻找更大的市场呢？它是如何度过20世纪90年代网络泡沫的呢？毕竟，从Twitter到Salesforce.com，当今所有的这些企业都在努力创建内部方案来解决25年前TIB就已经解决的PubSub问题。一句话：供应商壁垒。商业MQ供应商想要解决应用互通的问题，而不是去创建标准的接口来允许不同的MQ产品互通，或者（但愿不是这样）允许应用程序来更改MQ平台。供应商壁垒维持着足够搞得价格和利润率，并使得这些商业MQ软件对那些当今繁荣昌盛的初创公司Web 2.0公司来说遥不可及。

结果，中小技术公司并不是唯一一个对高价格MQ供应商感到不满的。那些早就MQ产业的金融服务公司对此也激动不起来。越是大型的金融公司越不可避免地使用来自众多供应商的MQ产品，来服务企业内部的不同应用。如果应用已经订阅了TIBCO MQ信息，若突然需要消费者来自IBM MQ的消息，则实现起来会非常困难。这些产品使用不同的API、不同协议，因而毫无疑问无法联合起来组成单一的总线。为了解决这个问题，Java Message Service(JMS)在2001年诞生了。JMS试图通过公共Java API的方式，隐藏单独MQ产品供应商提供的实际接口，从而跨越了壁垒和解决了互通问题。从技术上讲，Java应用程序只需针对JMS API编程，选择合适的MQ驱动即可。JMS会打理好其他部分。问题是你在尝试使用单独的标准化接口来胶合众多不同的接口。这就像是不同类型的衣服黏在一起：缝合处终究会裂开，真相会暴露出来。使用JMS的应用程序会变得更加脆弱。我们需要新的消息通信标准化方案。

### 6.1 救世主AMQP
2004年，JPMorgan Chase需要一个更好的消息通信解决方案，并开始和iMatix公司一起合作开发Advanced Message Queuing Protocol。AMQP从一开始就设计成开放标准，已解决众多的消息队列需求和拓扑结构问题。凭借开放，任何人都可以执行这一标准，针对标准编码的任何人都可以和任意AMQP供应商提供的MQ服务器进行交互。

在很多方面，AMQP承诺把我们从厂商的“地下城”中解决出来，并且实现Ranadive最初的愿景：从任何发布者到任何感兴趣的消费者之间的信息，通过一条软件总线实时动态连接起来。

### 6.2 RabbitMQ简史
在本世纪初，以为年轻的伦敦金融部门的企业家创办了一家专门研究Java对象缓存的公司：Metalogic。对Alexis Richardson来说，理论很简单：使用Java对象做分布式计算，同时为了传输性能对它们进行缓存。事实上却大相径庭。不同版本的虚拟机，以及客户端和服务器端不同的类库，都会使得接收到的对象不可用。Metalogic方法论的成功之路需要面对现实世界中太多的环境变数。Metalogic促成了Alexis和Matthias Radestock的会面。

Matthias在LShift工作，而Alexis正巧也在那里转租了一间办公室。当时LShift正投入和一家大型软件供应商的合同，专注于语言建模和分布式计算。这些领域方面的背景触发了Matthias对Erlang的兴趣。Erlang是Ericsson原本为电话交换机而开发的编程语言。引起Matthias注意的是Erlang在分布式编程和健壮性的故障恢复方面表现出色。可惜的是，当时Erlang不是开源的。同时，Metalogic结束了运营，LShift的主要分布式计算合同也接近尾声。Alexis在Metalogic的经历中学到了非常有价值的两课：分布式计算环境的工作机制和哪些公司需要这些环境。

Alexis知道自己想要开一家新的公司去解决分布式计算下的通信问题。他也知道他开的下一家公司将会是开源的，并且将采用JBoss和MySQL成功实践的模型。回顾Metalogic解决方案碰到的问题，Alexis逐渐认识到消息通信才是分布式计算的解决方案。更重要的是，2004年左右的技术领域正面临开源消息通信的空白。除了商业供应商外，没有人提供消息通信的解决方案。“企业”开源在数据库（MySQL）和应用服务器方面（JBoss）热火朝天，但却没有人去触碰消息通信那片空白。有趣的是：就在2004年，在JPMorgan Chase，AMQP正开始开发。因为在金融行业的背景，Alexis被引荐给了在JPMorgan的AMQP主要驱动者John O'Hara（将来的AMQP工作组创始人）。通过O'Hara，Alexis接触到了AMQP，并开始着手构建RabbitMQ。

在2005年左右，Alexis创办了CohesiveFT。他和他的合伙人在美国开办了公司，提供应用栈和工具，在今天逐渐成为云计算。对Alexis来说，应用栈的最关键部分是分布式消息通信。他（仍然在LShift那里办公）开始找Matthias探讨AMQP。Matthias清楚他已经找到了想要用Erlang实现的应用。但在动手之前，Alexis和Matthias聚焦在三个问题上。这三个问题是决定了用Erlang实现的AMQP开源版本能否成功的关键：
  * 那些大型金融机构是否会在意它们的消息代理服务器使用Erlang语言编写的？
  * Erlang语言是否真的是编写AMQP服务器的最佳选择？
  * 如果采用Erlang语言编写的话，是否会影响开源社区对它的采纳？
第一个问题立马就被一家金融公司解决了：他们不在乎软件是用什么语言编写的，只要它能够帮助减少集成上的花费即可。第二个问题由就职于Erlang Solutions的Francesco Cesarini回答：从他对AMQP的分析来看，这份规格说明展现的就是每一部电话交换机的架构。换句话说，你无法找到比Erlang更好的实现语言来构造AMQP代理服务器。最后一个问题则是被完全不同的消息通信服务区ejabberd解决了。知道2005年，Extensible Messaging and Presence Protocol（XMPP）已经逐渐成为受人尊敬的开放即时通信标准，并且首选的实现就是Alexey Shchepin编写的基于Erlang的ejabberd服务器包。ejabberd被广泛的使用在众多不同的组织机构里。它是由Erlang实现的这一点似乎并未阻挡其流行的步伐。

通过解决这三个主要问题，Alexis和Matthias说服了CohesiveFT和LShift共同支持这个项目。他们首先做的是签约Matthew Sackman（他现在是Rabbit核心开发员），让他用Erlang写了一个原型测试网络延迟。他们很快就发现用Erlang编写的分布式计算库有着和原生socket一样的延迟，简直不可思议。他们对名称很快有了共识：所有人都认可Rabbit这个名字。毕竟，兔子是行动非常迅速的动物且繁殖起来也非常疯狂，把它用于分布式软件的命名再合适不过了。至少选择Rabbit这个名字也便于记忆。因此在2006年，Rabbit Technologies诞生了：一家由CohesiveFT和LShift的合资企业，其拥有着RabbitMQ的知识产权。

时机总是如此的恰到好处，就在当时，AMQP规范的第一份公开草案也公之于世了。作为一份新的规范，AMQP正快速修订。这正是Erlang可以施展拳脚的地方。通过使用Erlang，RabbitMQ可以快速开发并跟上AMQP标准前进的节奏。令人惊讶的是，核心开发人员Tony Garnock-Jones仅仅用了两个半月的时间就将RabbitMQ 1.0版本开发完成了。最初，RabbitMQ实现了AMQP的一个关键特性，使其有别于TIBCO和IBM：使用协议本身就可以对像队列和交换器这样的资源进行配置。对商业供应商来说，资源配置需要通过特定的管理终端的特定工具才可以完成。RabbitMQ的资源配置能力使其成为构建分布式应用的最完美的通信总线，特别有助于充分利用基于云的资源和快速开发。

就这样一直到今天，RabbitMQ广泛使用在小到硅谷的初创公司，大到互联网巨头。对RabbitMQ来说，那也许是最好的事了，创始人感到非常惊讶：Rabbit的客户主要是技术公司而并非金融公司。对于那些只有少量预算同时也要解决消息通信的人来说，RabbitMQ实现了Ranadive的愿景。那正是RabbitMQ吸引我们的地方。我们并不知道自己是在找寻消息队列软件。我们知道的是自己需要解决应用集成和高强度事务处理负载的问题。RabbitMQ为我们提供了一个强大的工具来解决那些问题，并给我们带来了一段丰富的消息通信历史，以及适合所有人的可插拔的信息总线。

## 7 如何选择消息队列？
首先，必须是开源的产品，这个非常重要。开源意味着，如果有一天你使用的消息队列遇到了一个影响你系统业务的 Bug，你至少还有机会通过修改源代码来迅速修复或规避这个 Bug，解决你的系统火烧眉毛的问题，而不是束手无策地等待开发者不一定什么时候发布的下一个版本来解决。

其次，这个产品必须是近年来比较流行并且有一定社区活跃度的产品。流行的好处是，只要你的使用场景不太冷门，你遇到 Bug 的概率会非常低，因为大部分你可能遇到的 Bug，其他人早就遇到并且修复了。你在使用过程中遇到的一些问题，也比较容易在网上搜索到类似的问题，然后很快的找到解决方案。

还有一个优势就是，流行的产品与周边生态系统会有一个比较好的集成和兼容，比如，Kafka 和 Flink 就有比较好的兼容性，Flink 内置了 Kafka 的 Data Source，使用 Kafka 就很容易作为 Flink 的数据源开发流计算应用，如果你用一个比较小众的消息队列产品，在进行流计算的时候，你就不得不自己开发一个 Flink 的 Data Source。

最后，作为一款及格的消息队列产品，必须具备的几个特性包括：消息的可靠传递：确保不丢消息；Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；性能：具备足够好的性能，能满足绝大多数场景的性能要求。

### 7.1 RabbitMQ
老牌儿消息队列 RabbitMQ是使用一种比较小众的编程语言Erlang 语言编写的消息队列，它最早是为电信行业系统之间的可靠通信设计的，是少数几个支持 AMQP 协议的消息队列之一。它是一个轻量级、迅捷、开箱即用非常容易部署和使用轻量级的消息队列。

RabbitMQ 一个比较有特色的功能是支持非常灵活的路由配置，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个 Exchange（交换机）模块。

这个 Exchange 模块的作用和交换机也非常相似，根据配置的路由规则将生产者发出的消息分发到不同的队列中。路由的规则也非常灵活，甚至你可以自己来实现路由规则。基于这个 Exchange，可以产生很多的玩儿法，如果你正好需要这个功能，RabbitMQ 是个不错的选择。

RabbitMQ 的客户端支持的编程语言大概是所有消息队列中最多的，如果你的系统是用某种冷门语言开发的，那你多半可以找到对应的 RabbitMQ 客户端。

接下来说下 RabbitMQ 的几个问题。

- 第一个问题是，RabbitMQ 对消息堆积的支持并不好，在它的设计理念里面，消息队列是一个管道，大量的消息积压是一种不正常的情况，应当尽量去避免。当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。

- 第二个问题是，RabbitMQ 的性能是我们介绍的这几个消息队列中最差的，根据官方给出的测试数据综合我们日常使用的经验，依据硬件配置的不同，它大概每秒钟可以处理几万到十几万条消息。其实，这个性能也足够支撑绝大多数的应用场景了，不过，如果你的应用对消息队列的性能要求非常高，那不要选择 RabbitMQ。

- 最后一个问题是 RabbitMQ 使用的编程语言 Erlang，这个编程语言不仅是非常小众的语言，更麻烦的是，这个语言的学习曲线非常陡峭。大多数流行的编程语言，比如 Java、C/C++、Python 和 JavaScript，虽然语法、特性有很多的不同，但它们基本的体系结构都是一样的，你只精通一种语言，也很容易学习其他的语言，短时间内即使做不到精通，但至少能达到“会用”的水平。
就像一个以英语为母语的人，学习法语、德语都很容易，但是你要是让他去学汉语，那基本上和学习其他这些语言不是一个难度级别的。很不幸的是，Erlang 就是编程语言中的“汉语”。所以如果你想基于 RabbitMQ 做一些扩展和二次开发什么的，建议你慎重考虑一下可持续维护的问题。

### 7.2 RocketMQ

RocketMQ 是阿里巴巴在 2012 年开源的消息队列产品，后来捐赠给 Apache 软件基金会，2017 正式毕业，成为 Apache 的顶级项目。阿里内部也是使用 RocketMQ 作为支撑其业务的消息队列，经历过多次“双十一”考验，它的性能、稳定性和可靠性都是值得信赖的。作为优秀的国产消息队列，近年来越来越多的被国内众多大厂使用。

在总结 RocketMQ 的特点时，发现很难找出 RocketMQ 有什么特别让人印象深刻的特点，也很难找到它有什么缺点。

RocketMQ 就像一个品学兼优的好学生，有着不错的性能，稳定性和可靠性，具备一个现代的消息队列应该有的几乎全部功能和特性，并且它还在持续的成长中。

RocketMQ 有非常活跃的中文社区，大多数问题你都可以找到中文的答案，也许会成为你选择它的一个原因。另外，RocketMQ 使用 Java 语言开发，它的贡献者大多数都是中国人，源代码相对也比较容易读懂，你很容易对 RocketMQ 进行扩展或者二次开发。

RocketMQ 对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，**如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ**。

RocketMQ 的性能比 RabbitMQ 要高一个数量级，每秒钟大概能处理几十万条消息。

RocketMQ 的一个劣势是，作为国产的消息队列，相比国外的比较流行的同类产品，在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹。

### 7.3 Kafka

Kafka 最早是由 LinkedIn 开发，目前也是 Apache 的顶级项目。Kafka 最初的设计目的是用于处理海量的日志。

在早期的版本中，为了获得极致的性能，在设计方面做了很多的牺牲，比如不保证消息的可靠性，可能会丢失消息，也不支持集群，功能上也比较简陋，这些牺牲对于处理海量日志这个特定的场景都是可以接受的。这个时期的 Kafka 甚至不能称之为一个合格的消息队列。

但是，请注意，重点一般都在后面。在随后的几年 Kafka 逐步补齐了这些短板，网上很多消息队列的对比文章还在说 Kafka 不可靠，其实这种说法早已经过时了。当下的 Kafka 已经发展为一个非常成熟的消息队列产品，无论在数据可靠性、稳定性和功能特性等方面都可以满足绝大多数场景的需求。

**Kafka 是与周边生态系统的兼容性是最好的消息队列，没有之一，尤其在大数据和流计算领域，几乎所有的相关开源软件系统都会优先支持 Kafka。**

Kafka 使用 Scala 和 Java 语言开发，设计上大量使用了批量和异步的思想，这种设计使得 Kafka 能做到超高的性能。Kafka 的性能，尤其是异步收发的性能，是三者中最好的，但与 RocketMQ 并没有量级上的差异，大约每秒钟可以处理几十万条消息。

有大厂架构师曾经使用配置比较好的服务器对 Kafka 进行过压测，在有足够的客户端并发进行异步批量发送，并且开启压缩的情况下，Kafka 的极限处理能力可以超过每秒 2000 万条消息。

但是 Kafka 这种异步批量的设计带来的问题是，它的同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。

### 7.4 总结

- 如果说，消息队列并不是你将要构建系统的主角之一，你对消息队列功能和性能都没有很高的要求，只需要一个开箱即用易于维护的产品，我建议你使用 RabbitMQ。

- 如果你的系统使用消息队列主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，那 RocketMQ 的低延迟和金融级的稳定性是你需要的。

- 如果你需要处理海量的消息，像收集日志、监控信息或是前端的埋点这类数据，或是你的应用场景大量使用了大数据、流计算相关的开源产品，那 Kafka 是最适合你的消息队列。
## 8 消息队列模型

每种消息队列都有自己的一套消息模型，像队列（Queue）、主题（Topic）或是分区（Partition）这些名词概念，在每个消息队列模型中都会涉及一些，含义还不太一样。

为什么出现这种情况呢？因为没有标准。曾经，也是有一些国际组织尝试制定过消息相关的标准，比如早期的 JMS 和 AMQP。但让人无奈的是，标准的进化跟不上消息队列的演进速度，这些标准实际上已经被废弃了。

### 8.1 队列模型

![Message Queue Model](https://github.com/meiyingqishi/Images/blob/main/queue-model.jpg)

生产者（Producer）发消息就是入队操作，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。这就是最初的一种消息模型：队列模型。

如果有多个生产者往同一个队列里面发送消息，这个队列中可以消费到的消息，就是这些生产者生产的所有消息的合集。消息的顺序就是这些生产者发送消息的自然顺序。如果有多个消费者接收同一个队列的消息，这些消费者之间实际上是竞争的关系，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。

如果需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，例如，对于一份订单数据，风控系统、分析系统、支付系统等都需要接收消息。这个时候，单个队列就满足不了需求，一个可行的解决方式是，为每个消费者创建一个单独的队列，让生产者发送多份。

显然这是个比较蠢的做法，同样的一份消息数据被复制到多个队列中会浪费资源，更重要的是，生产者必须知道有多少个消费者。为每个消费者单独发送一份消息，这实际上违背了消息队列“解耦”这个设计初衷。

为了解决这个问题，演化出了另外一种消息模型：“发布 - 订阅模型（Publish-Subscribe Pattern）”。（8.2再讲）

**RabbitMQ 的消息模型**

![RabbitMQ Message Model](https://github.com/meiyingqishi/Images/blob/main/rabbitmq-message-model.jpg)

RabbitMQ，它是少数依然坚持使用队列模型的产品之一。那它是怎么解决多个消费者的问题呢？使用交换机。在 RabbitMQ 中，Exchange 位于生产者和队列之间，生产者并不关心将消息发送给哪个队列，而是将消息发送给 Exchange，由 Exchange 上配置的策略来决定将消息投递到哪些队列中。

同一份消息如果需要被多个消费者来消费，需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相地实现新发布 - 订阅模型中，“一份消息数据可以被多个订阅者来多次消费”这样的功能。

### 8.2 发布订阅模型

![publisher subscriber Model](https://github.com/meiyingqishi/Images/blob/main/publisher-subscriber-model.jpg)

在发布 - 订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

在消息领域的历史上很长的一段时间，队列模式和发布 - 订阅模式是并存的，有些消息队列同时支持这两种消息模型，比如 ActiveMQ。我们仔细对比一下这两种模型，生产者就是发布者，消费者就是订阅者，队列就是主题，并没有本质的区别。它们最大的区别其实就是，一份消息数据能不能被消费多次的问题。

实际上，在这种发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。也就是说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。

现代的消息队列产品使用的消息模型大多是这种发布 - 订阅模型。

**RocketMQ 的消息模型**

![RocketMQ Message Model](https://github.com/meiyingqishi/Images/blob/main/rocketmq-message-model.jpg)

RocketMQ 使用的消息模型是标准的发布 - 订阅模型，在 RocketMQ 的术语表中，生产者、消费者和主题与上面讲的发布 - 订阅模型中的概念是完全一样的。

但是，在 RocketMQ 也有队列（Queue）这个概念，并且队列在 RocketMQ 中是一个非常重要的概念，那队列在 RocketMQ 中的作用是什么呢？这就要从消息队列的消费机制说起。

几乎所有的消息队列产品都使用一种非常朴素的“请求 - 确认”机制，确保消息不会在传递过程中由于网络或服务器故障丢失。具体的做法也非常简单。在生产端，生产者先将消息发送给服务端，也就是 Broker，服务端在收到消息并将消息写入主题或者队列中后，会给生产者发送确认的响应。

如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；在消费端，消费者在收到消息并完成自己的消费业务逻辑（比如，将数据保存到数据库中）后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

这个确认机制很好地保证了消息传递过程中的可靠性，但是，引入这个机制在消费端带来了一个不小的问题。什么问题呢？为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现消息空洞，违背了有序性这个原则。

也就是说，每个主题在任意时刻，至多只能有一个消费者实例在进行消费，那就没法通过水平扩展消费者的数量来提升消费端总体的消费性能。为了解决这个问题，RocketMQ 在主题下面增加了队列的概念。

每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。需要注意的是，RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。

RocketMQ 中，订阅者的概念是通过消费组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。

消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。如果一条消息被消费者 Consumer1 消费了，那同组的其他消费者就不会再收到这条消息。

在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，我们在使用消息队列的时候，丢消息的原因大多是由于消费位置处理不当导致的。

**Kafka 的消息模型**

Kafka 的消息模型和 RocketMQ 是完全一样的，上面讲的所有 RocketMQ 中对应的概念，和生产消费过程中的确认机制，都完全适用于 Kafka。唯一的区别是，在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能是没有任何区别的。

## 9 如何确保消息不会丢失?

- **生产阶段：** 

> 在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。

> 在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。

> 在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。

- **存储阶段：**

> 在存储阶段正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题，但是如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。

> 如果对消息的可靠性要求非常高，可以通过配置 Broker 参数来避免因为宕机丢消息。
> 对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。

> 如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。

- **消费阶段：**

> 消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。

> 在编写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。

## 10 如何处理消费过程中的重复消息？

> 幂等：其任意多次执行所产生的影响均与一次执行的影响相同。

- **利用数据库的唯一约束实现幂等。**

- **为更新的数据设置前置条件：** 给数据变更设置一个前置条件，如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。

    但是，如果我们要更新的数据不是数值，或者我们要做一个比较复杂的更新操作怎么办？用什么作为前置判断条件呢？更加通用的方法是，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新。

- **记录并检查操作：** 如果上面提到的两种实现幂等方法都不能适用于你的场景，我们还有一种通用性最强，适用范围最广的实现幂等性方法：记录并检查操作，也称为“Token 机制或者 GUID（全局唯一 ID）机制”，实现的思路特别简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。
    
    具体的实现方法是，在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。
    
    在分布式系统中，这个方法其实是非常难实现。首先，给每个消息指定一个全局唯一的 ID 就是一件不那么简单的事儿，方法有很多，但都不太好同时满足简单、高可用和高性能，或多或少都要有些牺牲。更加麻烦的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug。
    
    对于这个问题，当然我们可以用事务来实现，也可以用锁来实现，但是在分布式系统中，无论是分布式事务还是分布式锁都是比较难解决问题。
    
## 11 消息积压了该如何处理？ 

> 优化性能来避免消息积压。

- **发送端性能优化：** 发送端业务代码的处理性能，实际上和消息队列的关系不大，因为一般发送端都是先执行自己的业务逻辑，最后再发送消息。如果说，你的代码发送消息的性能上不去，需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的。

- **消费端性能优化：** 使用消息队列的时候，大部分的性能问题都出现在消费端，如果消费的速度跟不上发送端生产消息的速度，就会造成消息积压。如果这种性能倒挂的问题只是暂时的，那问题不大，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。

	要是消费速度一直比生产速度慢，时间长了，整个系统就会出现问题，要么，消息队列的存储被填满无法提供服务，要么消息丢失，这对于整个系统来说都是严重故障。
	
	所以，我们在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。
	
	消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是，在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。因为对于消费者来说，在每个分区上实际上只能支持单线程消费。
	
**原因：**

- 发送变快了。
- 消费变慢了。

**解决方案：**

- 通过内置的监控功能监控数据。

- 查日志、打印堆栈进行分析原因（死锁、卡在资源等待）。

- 扩容消费端的实例数来提升总体的消费能力。

- 系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。

## 12 实现消息队列的一些技术

- 采用异步实现解决等待问题。
- 使用 Netty 来实现异步网络通信。
- 自定义实现高性能的序列化和反序列化。
- 传输协议：
	- 预置长度断句。
	- 用双工收发协议提升吞吐量。
- 内存管理：
	- 尽量少的产生这种一次性对象。
	- 对象池。
	- 使用更大内存的服务器。
	- 绕开自动垃圾回收机制，自己来实现内存管理。（Flink）
	- 使用批量消息提升服务端处理能力。
	- 使用顺序读写提升磁盘 IO 性能。
	- 利用 PageCache 加速消息读写。
	- ZeroCopy：零拷贝技术。
	- 用硬件同步原语（CAS、FAA）替代锁。
	- 数据压缩（ZIP，GZIP，SNAPPY，LZ4）。
	
## 13 RabbitMQ基本操作

- 官网：https://www.rabbitmq.com
- 安装：https://www.rabbitmq.com/download.html
- 常规教程：https://www.rabbitmq.com/getstarted.html
- 与Spring boot集成的相关参考资源：
	+ https://spring.io/guides/gs/messaging-rabbitmq
	+ https://docs.spring.io/spring-amqp/docs/current/reference/html
	+ 使用例子：https://github.com/spring-projects/spring-amqp-samples

## 参考
* [1] https://www.cloudamqp.com/blog/2014-12-03-what-is-message-queuing.html
* [2] https://aws.amazon.com/cn/message-queue/
* [3] https://aws.amazon.com/message-queue/benefits/#:~:text=Message%20queues%20enable%20asynchronous%20communication,only%20when%20they%20are%20available.
* [4] https://www.erlang-solutions.com/blog/an-introduction-to-rabbitmq-what-is-rabbitmq/
